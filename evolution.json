{
  "3": {
    "inputs": {
      "seed": 4244721073,
      "steps": 4,
      "cfg": 1.3,
      "sampler_name": "dpmpp_sde",
      "scheduler": "karras",
      "denoise": 0.8,
      "model": [
        "567",
        0
      ],
      "positive": [
        "133",
        0
      ],
      "negative": [
        "138",
        0
      ],
      "latent_image": [
        "654",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "SDXL\\lightning turbo\\juggernautXL_v9Rdphoto2Lightning.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "133": {
    "inputs": {
      "text": "",
      "clip": [
        "367",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "138": {
    "inputs": {
      "text": "",
      "clip": [
        "367",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "367": {
    "inputs": {
      "stop_at_clip_layer": -2,
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP Set Last Layer"
    }
  },
  "411": {
    "inputs": {
      "image": "frog.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load end img"
    }
  },
  "425": {
    "inputs": {
      "image": "fish.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load start img"
    }
  },
  "427": {
    "inputs": {
      "image": "fish.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "559": {
    "inputs": {
      "images": [
        "8",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "567": {
    "inputs": {
      "weight": 1,
      "weight_type": "original",
      "start_at": 0,
      "end_at": 1,
      "unfold_batch": false,
      "ipadapter": [
        "570",
        0
      ],
      "embeds": [
        "569",
        0
      ],
      "model": [
        "4",
        0
      ]
    },
    "class_type": "IPAdapterApplyEncoded",
    "_meta": {
      "title": "Apply IPAdapter from Encoded"
    }
  },
  "569": {
    "inputs": {
      "ipadapter_plus": false,
      "noise": 0.2,
      "weight_1": 0.5,
      "weight_2": 0.5,
      "weight_3": 0,
      "weight_4": 0,
      "clip_vision": [
        "571",
        0
      ],
      "image_1": [
        "425",
        0
      ],
      "image_2": [
        "411",
        0
      ],
      "image_3": [
        "427",
        0
      ],
      "image_4": [
        "572",
        0
      ]
    },
    "class_type": "IPAdapterEncoder",
    "_meta": {
      "title": "Encode IPAdapter Image"
    }
  },
  "570": {
    "inputs": {
      "ipadapter_file": "ip-adapter_sdxl_vit-h.safetensors"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "Load IPAdapter Model"
    }
  },
  "571": {
    "inputs": {
      "clip_name": "small.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "572": {
    "inputs": {
      "image": "fish.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "651": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "8",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "652": {
    "inputs": {
      "image": "fish.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load first img"
    }
  },
  "653": {
    "inputs": {
      "pixels": [
        "652",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "654": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 1024,
      "height": 1024,
      "crop": "disabled",
      "samples": [
        "653",
        0
      ]
    },
    "class_type": "LatentUpscale",
    "_meta": {
      "title": "Upscale Latent"
    }
  }
}