{
  "3": {
    "inputs": {
      "seed": 1034983277368648,
      "steps": 6,
      "cfg": 1.5,
      "sampler_name": "euler_ancestral",
      "scheduler": "sgm_uniform",
      "denoise": 1,
      "model": [
        "57",
        0
      ],
      "positive": [
        "21",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "85",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "dreamshaperXL_lightningDPMSDE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "6": {
    "inputs": {
      "text": "",
      "clip": [
        "30",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "text, watermark, empty, boring, NSFW, nude",
      "clip": [
        "30",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "12": {
    "inputs": {
      "pixels": [
        "106",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "15": {
    "inputs": {
      "image": "ComfyUI_temp_tjtgh_00006_.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "19": {
    "inputs": {
      "text": "",
      "clip": [
        "30",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "21": {
    "inputs": {
      "conditioning_to_strength": 0,
      "conditioning_to": [
        "19",
        0
      ],
      "conditioning_from": [
        "6",
        0
      ]
    },
    "class_type": "ConditioningAverage",
    "_meta": {
      "title": "ConditioningAverage"
    }
  },
  "22": {
    "inputs": {
      "lora_name": {
        "content": "VnC_beta.safetensors",
        "image": null
      },
      "strength_model": 0.8,
      "strength_clip": 1,
      "example": "[none]",
      "model": [
        "4",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "LoraLoader|pysssss",
    "_meta": {
      "title": "Lora Loader ??"
    }
  },
  "28": {
    "inputs": {
      "images": [
        "29",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "29": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "30": {
    "inputs": {
      "lora_name": {
        "content": "VnC_beta.safetensors",
        "image": null
      },
      "strength_model": 0,
      "strength_clip": 0,
      "example": "[none]",
      "model": [
        "22",
        0
      ],
      "clip": [
        "22",
        1
      ]
    },
    "class_type": "LoraLoader|pysssss",
    "_meta": {
      "title": "Lora Loader ??"
    }
  },
  "33": {
    "inputs": {
      "ipadapter_file": "ip-adapter_sdxl_vit-h.safetensors"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "Load IPAdapter Model"
    }
  },
  "34": {
    "inputs": {
      "weight": 0.9,
      "weight_type": "channel penalty",
      "start_at": 0.3,
      "end_at": 1,
      "unfold_batch": false,
      "ipadapter": [
        "33",
        0
      ],
      "embeds": [
        "35",
        0
      ],
      "model": [
        "30",
        0
      ]
    },
    "class_type": "IPAdapterApplyEncoded",
    "_meta": {
      "title": "Apply IPAdapter from Encoded"
    }
  },
  "35": {
    "inputs": {
      "ipadapter_plus": false,
      "noise": 0.3,
      "weight_1": 0.9,
      "weight_2": 0,
      "weight_3": 0.8,
      "weight_4": 0,
      "clip_vision": [
        "36",
        0
      ],
      "image_1": [
        "37",
        0
      ],
      "image_2": [
        "38",
        0
      ],
      "image_3": [
        "39",
        0
      ],
      "image_4": [
        "40",
        0
      ]
    },
    "class_type": "IPAdapterEncoder",
    "_meta": {
      "title": "Encode IPAdapter Image"
    }
  },
  "36": {
    "inputs": {
      "clip_name": "small.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "37": {
    "inputs": {
      "image": "sumin1.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "38": {
    "inputs": {
      "image": "mmexport1586689643614.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "39": {
    "inputs": {
      "image": "sumin4.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "40": {
    "inputs": {
      "image": "sumin3.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "57": {
    "inputs": {
      "weight": 0.8,
      "weight_type": "channel penalty",
      "start_at": 0,
      "end_at": 0.2,
      "unfold_batch": false,
      "ipadapter": [
        "33",
        0
      ],
      "embeds": [
        "58",
        0
      ],
      "model": [
        "34",
        0
      ]
    },
    "class_type": "IPAdapterApplyEncoded",
    "_meta": {
      "title": "Apply IPAdapter from Encoded"
    }
  },
  "58": {
    "inputs": {
      "ipadapter_plus": false,
      "noise": 0.3,
      "weight_1": 1,
      "weight_2": 0,
      "weight_3": 0,
      "weight_4": 0,
      "clip_vision": [
        "36",
        0
      ],
      "image_1": [
        "60",
        0
      ],
      "image_2": [
        "81",
        0
      ],
      "image_3": [
        "61",
        0
      ],
      "image_4": [
        "62",
        0
      ]
    },
    "class_type": "IPAdapterEncoder",
    "_meta": {
      "title": "Encode IPAdapter Image"
    }
  },
  "60": {
    "inputs": {
      "image": "ComfyUI_temp_yktih_00001_.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "61": {
    "inputs": {
      "image": "sumin4.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "62": {
    "inputs": {
      "image": "night.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "69": {
    "inputs": {
      "left": 16,
      "top": 8,
      "right": 16,
      "bottom": 8,
      "feathering": 90,
      "image": [
        "15",
        0
      ]
    },
    "class_type": "ImagePadForOutpaint",
    "_meta": {
      "title": "Pad Image for Outpainting"
    }
  },
  "70": {
    "inputs": {
      "enabled": true,
      "swap_model": "inswapper_128.onnx",
      "facedetection": "retinaface_resnet50",
      "face_restore_model": "codeformer.pth",
      "face_restore_visibility": 1,
      "codeformer_weight": 0.5,
      "detect_gender_source": "no",
      "detect_gender_input": "no",
      "source_faces_index": "0",
      "input_faces_index": "0",
      "console_log_level": 1,
      "input_image": [
        "127",
        0
      ],
      "source_image": [
        "71",
        0
      ]
    },
    "class_type": "ReActorFaceSwap",
    "_meta": {
      "title": "ReActor - Fast Face Swap"
    }
  },
  "71": {
    "inputs": {
      "image": "sumin4.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "74": {
    "inputs": {
      "images": [
        "70",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "80": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "128",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "81": {
    "inputs": {
      "image": "ComfyUI_temp_yktih_00001_.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "85": {
    "inputs": {
      "samples": [
        "12",
        0
      ],
      "mask": [
        "95",
        0
      ]
    },
    "class_type": "SetLatentNoiseMask",
    "_meta": {
      "title": "Set Latent Noise Mask"
    }
  },
  "90": {
    "inputs": {
      "upscale_method": "bicubic",
      "width": 1344,
      "height": 768,
      "crop": "disabled"
    },
    "class_type": "LatentUpscale",
    "_meta": {
      "title": "Upscale Latent"
    }
  },
  "95": {
    "inputs": {
      "channel": "blue",
      "image": [
        "102",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "101": {
    "inputs": {
      "mask": [
        "129",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "102": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 1344,
      "height": 768,
      "crop": "disabled",
      "image": [
        "101",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image"
    }
  },
  "104": {
    "inputs": {
      "samples": [
        "12",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "106": {
    "inputs": {
      "upscale_method": "bilinear",
      "width": 1344,
      "height": 768,
      "crop": "disabled",
      "image": [
        "69",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image"
    }
  },
  "113": {
    "inputs": {
      "images": [
        "104",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "118": {
    "inputs": {
      "x": 0,
      "y": 0,
      "resize_source": false,
      "destination": [
        "106",
        0
      ],
      "source": [
        "29",
        0
      ],
      "mask": [
        "95",
        0
      ]
    },
    "class_type": "ImageCompositeMasked",
    "_meta": {
      "title": "ImageCompositeMasked"
    }
  },
  "123": {
    "inputs": {
      "seed": 561284598450499,
      "steps": 6,
      "cfg": 1.5,
      "sampler_name": "euler_ancestral",
      "scheduler": "sgm_uniform",
      "denoise": 0.43,
      "model": [
        "57",
        0
      ],
      "positive": [
        "21",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "124",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "124": {
    "inputs": {
      "pixels": [
        "118",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "126": {
    "inputs": {
      "images": [
        "127",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "127": {
    "inputs": {
      "samples": [
        "123",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "128": {
    "inputs": {
      "text": "@ wisieeen293",
      "align": "bottom left",
      "opacity": 0.5,
      "font_name": "AlumniSansCollegiateOne-Regular.ttf",
      "font_size": 80,
      "font_color": "custom",
      "x_margin": 20,
      "y_margin": 20,
      "font_color_hex": "#000000",
      "image": [
        "70",
        0
      ]
    },
    "class_type": "CR Simple Text Watermark",
    "_meta": {
      "title": "CR Simple Text Watermark"
    }
  },
  "129": {
    "inputs": {
      "expand": 2,
      "tapered_corners": true,
      "mask": [
        "69",
        1
      ]
    },
    "class_type": "GrowMask",
    "_meta": {
      "title": "GrowMask"
    }
  },
  "130": {
    "inputs": {
      "images": [
        "102",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  }
}